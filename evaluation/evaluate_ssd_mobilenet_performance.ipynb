{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c655849c-5540-400a-9f56-7bd14b4d1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 \n",
    "import time  \n",
    "from memory_profiler import memory_usage\n",
    "sys.path.append(\"../inference\")\n",
    "from ssd_mobilenet_tflite_inference import SSDMobileNetTFLiteDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efdb737-3518-43e8-aeeb-0ac043ad6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load labels from a file into a dictionary.\n",
    "\n",
    "    Args:\n",
    "        labels_path (str): Path to the label file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping class indices to class names.\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    with open(labels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            idx, label = line.strip().split(maxsplit=1)\n",
    "            labels[int(idx)] = label\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79310a28-be48-47b4-8b2b-e958ba7d52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_process(detector, input_frame_rgb):\n",
    "    \"\"\"\n",
    "    Perform an inference process using an object detector.\n",
    "    \n",
    "    This function runs an inference process on a provided input image using\n",
    "    an object detector. The inference time is measured in milliseconds.\n",
    "    \n",
    "    Args:\n",
    "        detector (object): An object detector that must have a `detect_objects` method.\n",
    "        input_frame_rgb (numpy.ndarray): A color image in RGB format on which inference will be performed.\n",
    "    \n",
    "    Returns:\n",
    "        float: The inference time in milliseconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    num_detections, boxes, classes, scores = detector.detect_objects(input_frame_rgb)\n",
    "    inference_time = (time.time() - start_time) * 1000 \n",
    "\n",
    "\n",
    "    return inference_time\n",
    "    \n",
    "def profile_function(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Profile the memory usage of a function.\n",
    "\n",
    "    This function measures the memory usage of a given function using the\n",
    "    memory_usage function from the `memory_profiler` library.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to be profiled.\n",
    "        *args: Variable length argument list for the function.\n",
    "        **kwargs: Arbitrary keyword arguments for the function.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of adjusted memory usage measurements over time.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use memory_usage to measure the memory usage of the function\n",
    "    mem_usage = memory_usage((func, args, kwargs), interval=0.0001)\n",
    "\n",
    "    # Adjust memory usage to start from zero\n",
    "    min_mem_usage = min(mem_usage)\n",
    "\n",
    "    # Subtract the initial memory from the measurements\n",
    "    adjusted_mem_usage = [mem - min_mem_usage for mem in mem_usage]\n",
    "\n",
    "    return adjusted_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f9713f-b25a-40ce-a88a-65eb4c495591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_performance(source: str, model_path: str, labels_path: str, confidence_threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Processes a video file or stream to perform object detection using a specified model, and measures performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        source (str): The path to the video file or a camera index (if using a webcam).\n",
    "        model_path (str): The path to the object detection model file.\n",
    "        labels_path (str): The path to the file containing class labels.\n",
    "        confidence_threshold (float): The confidence threshold for filtering detected objects. Default is 0.5.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = load_labels(labels_path)\n",
    "    detector = SSDMobileNetTFLiteDetector(model_path)\n",
    "\n",
    "    if source.isdigit():\n",
    "        cap = cv2.VideoCapture(int(source))\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video file.\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0\n",
    "    total_detections = 0\n",
    "    total_inference_time = 0.0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        input_frame = cv2.resize(frame, (300, 300))\n",
    "        input_frame_rgb = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # DÃ©tection d'objets\n",
    "        start_time = time.time()\n",
    "        num_detections, boxes, classes, scores = detector.detect_objects(input_frame_rgb)\n",
    "        inference_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        total_detections += num_detections\n",
    "        total_inference_time += inference_time\n",
    "        \n",
    "        for i in range(num_detections):\n",
    "            if scores[i] > 0.5:\n",
    "                box = boxes[i]\n",
    "                y_min, x_min, y_max, x_max = int(box[0] * frame.shape[0]), int(box[1] * frame.shape[1]), int(box[2] * frame.shape[0]), int(box[3] * frame.shape[1])\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                \n",
    "                label = labels.get(int(classes[i]), 'Unknown')\n",
    "                label_text = f'{label}: {scores[i]:.2f}'\n",
    "                cv2.putText(frame, label_text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        fps = 1000 / inference_time if inference_time > 0 else 0\n",
    "        cv2.putText(frame, f'FPS: {fps:.2f}, Inference Time: {inference_time:.2f}ms', \n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Object Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    avg_inference_time = total_inference_time / frame_count if frame_count > 0 else 0\n",
    "    print(f\"Processed {frame_count} frames.\")\n",
    "    print(f\"Total detections: {total_detections}\")\n",
    "    print(f\"Average inference time per frame: {avg_inference_time:.2f} ms\")\n",
    "    print(f\"Average FPS: {1000 / avg_inference_time:.2f}\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c45d30-827b-4d08-b550-8a5e21e7bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_memory_performance(source: str, model_path: str, labels_path: str, confidence_threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Processes a video file or stream to perform object detection and profiles memory usage.\n",
    "    \n",
    "    Args:\n",
    "        source (str): The path to the video file or a camera index (if using a webcam).\n",
    "        model_path (str): The path to the object detection model file.\n",
    "        labels_path (str): The path to the file containing class labels.\n",
    "        confidence_threshold (float): The confidence threshold for filtering detected objects. Default is 0.5.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = load_labels(labels_path)\n",
    "    detector = SSDMobileNetTFLiteDetector(model_path)\n",
    "\n",
    "    if source.isdigit():\n",
    "        cap = cv2.VideoCapture(int(source))\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video file.\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0\n",
    "    mem_usage_images = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        input_frame = cv2.resize(frame, (300, 300))\n",
    "        input_frame_rgb = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "        mem_usage_image = profile_function(inference_process, detector, input_frame_rgb)\n",
    "        \n",
    "        mem_usage_images.append(mem_usage_image)\n",
    "\n",
    "        cv2.imshow('Object Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "    print(f\"Processed {frame_count} frames.\")\n",
    "    print(f\"Profiling memory usage for object detection process with SSDMobileNetV1: {np.mean([np.max(test) for test in mem_usage_images])} MiB\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b252d-5347-4a5d-bc8e-b46ed72414af",
   "metadata": {},
   "source": [
    "## Performance evaluation of SSDMobileNetV1 a video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd024c59-f75f-4e65-ad68-51d9995f36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 45 frames.\n",
      "Total detections: 460\n",
      "Average inference time per frame: 33.43 ms\n",
      "Average FPS: 29.92\n"
     ]
    }
   ],
   "source": [
    "video_path = '../data/026c7465-309f6d33.mp4'\n",
    "model_path = '../models/ssd_mobilenet_tflite/ssd_mobilenet.tflite'\n",
    "label_path = '../models/label_map.txt'\n",
    "confidence_threshold = 0.6\n",
    "process_video_performance(video_path, model_path, label_path, confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446a4d3-34ac-4cbf-adaf-f09b9a9ac72d",
   "metadata": {},
   "source": [
    "## Analysis of model SSDMobileNetV1 memory usage on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb60e7f-9939-4a7e-9315-ba137b25f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17 frames.\n",
      "Profiling memory usage for object detection process with SSDMobileNetV1: 0.158203125 MiB\n"
     ]
    }
   ],
   "source": [
    "video_path = '../data/026c7465-309f6d33.mp4'\n",
    "model_path = '../models/ssd_mobilenet_tflite/ssd_mobilenet.tflite'\n",
    "label_path = '../models/label_map.txt'\n",
    "confidence_threshold = 0.6\n",
    "\n",
    "process_video_memory_performance(video_path, model_path, label_path, confidence_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
